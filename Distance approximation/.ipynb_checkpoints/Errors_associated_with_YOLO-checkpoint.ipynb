{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97178aa9",
   "metadata": {},
   "source": [
    "# Intialize notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e3b6dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.patches import Rectangle\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '../python_files/yolo_load_files')\n",
    "from predictor import get_estimations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "feec5b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ad25aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf3524c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "#KITTI_DATASET = '/media/javier/HDD_linux/KITTI_dataset/training/'\n",
    "KITTI_DATASET = '/media/robesafe/SSD_SATA/KITTI_DATASET/'\n",
    "WORK_PATH = os.getcwd()\n",
    "WEIGHTS_PATH = os.getcwd()+'/weights'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a2f4c8",
   "metadata": {},
   "source": [
    "# Run YOLOv5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e35da65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/ultralytics/yolov5/archive/master.zip\" to /home/robesafe/Javier/3D-detection-system-lidar-camera/Distance approximation/master.zip\n",
      "YOLOv5 ðŸš€ 2022-4-21 torch 1.10.2 CUDA:0 (NVIDIA GeForce GTX 1080 Ti, 11175MiB)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.0 required by YOLOv5, but Python 3.6.13 is currently installed\n",
      "Downloading https://github.com/ultralytics/yolov5/releases/download/v6.1/yolov5l.pt to yolov5l.pt...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a225203ba5a443292658cb05ec16379",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/89.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "YOLOv5l summary: 367 layers, 46533693 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/robesafe/Javier/3D-detection-system-lidar-camera/Distance approximation/weights'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-7adc85b64e90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0myolo_estimations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_estimations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKITTI_DATASET\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWORK_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWEIGHTS_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Javier/3D-detection-system-lidar-camera/python_files/yolo_load_files/predictor.py\u001b[0m in \u001b[0;36mget_estimations\u001b[0;34m(KITTI_DATASET, WORK_PATH, WEIGHTS_PATH, batch_size, threshold)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWORK_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0myolo_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ultralytics/yolov5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'yolov5l'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model_est\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWEIGHTS_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mestimations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Javier/3D-detection-system-lidar-camera/python_files/yolo_load_files/predictor.py\u001b[0m in \u001b[0;36mload_model_est\u001b[0;34m(dir)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_model_est\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mmodel_lst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_lst\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No previous model found, please train first!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/robesafe/Javier/3D-detection-system-lidar-camera/Distance approximation/weights'"
     ]
    }
   ],
   "source": [
    "yolo_estimations = get_estimations(KITTI_DATASET, WORK_PATH, WEIGHTS_PATH, batch_size=400, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455c2721",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_estimations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbaf1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_detecctions = []\n",
    "n_image = 0\n",
    "for image in yolo_estimations:\n",
    "    n_detecction = 0\n",
    "    for detecction in image:\n",
    "        obj_type = None\n",
    "        if detecction[2] == \"car\":\n",
    "            obj_type = \"Car\"\n",
    "        elif detecction[2] == \"person\":\n",
    "            obj_type = \"Pedestrian\"\n",
    "        elif detecction[2] == \"bicycle\":\n",
    "            obj_type = \"Cyclist\"\n",
    "        else:\n",
    "            continue\n",
    "        yolo_detecctions.append([n_image, n_detecction, obj_type, detecction[0][0], detecction[0][1],\n",
    "                                 detecction[1][0], detecction[1][1], detecction[3]])\n",
    "        n_detecction += 1\n",
    "    n_image += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4502fe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_detections = pd.DataFrame(columns=['frame','id','type','left','top','right','bottom','score'], data=yolo_detecctions)\n",
    "df_detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4491a12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bounding_boxes_2D(df, image_id):\n",
    "    df_frame = df[df['frame'] == image_id]\n",
    "    bbs = []\n",
    "    for index, row in df_frame.iterrows():\n",
    "        bb = (row['left'], row['top'], row['right'], row['bottom'], row['type'])\n",
    "        bbs.append(bb)\n",
    "    return bbs\n",
    "\n",
    "def show_bounding_boxes_2D(df, image_id):\n",
    "    name = '%06d'%image_id # 6 digit zeropadding\n",
    "    img = KITTI_DATASET+'images/'+name+'.png'\n",
    "    \n",
    "    # do projection staff\n",
    "    plt.figure(figsize=(12,5),dpi=96,tight_layout=True)\n",
    "    png = mpimg.imread(img)\n",
    "    IMG_H,IMG_W,_ = png.shape\n",
    "    # restrict canvas in range\n",
    "    plt.axis([0,IMG_W,IMG_H,0])\n",
    "    plt.imshow(png)\n",
    "    \n",
    "    # draw bounding boxes\n",
    "    bbs = get_bounding_boxes_2D(df, image_id)\n",
    "    for bb in bbs:\n",
    "        if bb[4] == 'Car':\n",
    "            color = 'red'\n",
    "        elif bb[4] == 'Pedestrian':\n",
    "            color = 'green'\n",
    "        elif bb[4] == 'Cyclist':\n",
    "            color = 'blue'\n",
    "        else:\n",
    "            color = 'yellow'\n",
    "        plt.gca().add_patch(Rectangle((bb[0], bb[1]),bb[2]-bb[0],bb[3]-bb[1],linewidth=1,edgecolor=color,facecolor='none'))\n",
    "    \n",
    "    # plt.savefig(WORK_PATH+'/yolo_images/{}.png'.format(name),bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b6f103",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_bounding_boxes_2D(df_detections, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8619bfac",
   "metadata": {},
   "source": [
    "# Associate GT with YOLOv5 detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9fa92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gt = pd.read_csv(KITTI_DATASET+'kitti_gt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7283efb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c271780",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_2d_overlap(bbox_gt, bbox_det):\n",
    "    \"\"\"\n",
    "    Calculate the overlap between two bounding boxes in 2D.\n",
    "\n",
    "    :param bbox_gt: (xmin, ymin, xmax, ymax)\n",
    "    :param bbox_det: (xmin, ymin, xmax, ymax)\n",
    "    :return: overlap: float\n",
    "    \"\"\"\n",
    "    # Calculate the area of the bounding boxes\n",
    "    area_gt = (bbox_gt[2] - bbox_gt[0]) * (bbox_gt[3] - bbox_gt[1])\n",
    "    area_det = (bbox_det[2] - bbox_det[0]) * (bbox_det[3] - bbox_det[1])\n",
    "    # Calculate the intersection of the areas\n",
    "    intersection = bbox_2d_intersection(bbox_gt, bbox_det)\n",
    "    # Calculate the union of the areas\n",
    "    union = area_gt + area_det - intersection\n",
    "    # Calculate the overlap\n",
    "    overlap = intersection / union\n",
    "    #print(overlap)\n",
    "    #print(\"#################\")\n",
    "    return overlap\n",
    "\n",
    "def bbox_2d_intersection(bbox_gt, bbox_det):\n",
    "    \"\"\"\n",
    "    Calculate the intersection of two bounding boxes in 2D.\n",
    "\n",
    "    :param bbox_gt: (xmin, ymin, xmax, ymax)\n",
    "    :param bbox_det: (xmin, ymin, xmax, ymax)\n",
    "    :return: intersection: float\n",
    "    \"\"\"\n",
    "    # Calculate the intersection\n",
    "    intersection = max(0, min(bbox_gt[2], bbox_det[2]) - max(bbox_gt[0], bbox_det[0])) * \\\n",
    "                   max(0, min(bbox_gt[3], bbox_det[3]) - max(bbox_gt[1], bbox_det[1]))\n",
    "    #print(bbox_gt)\n",
    "    #print(bbox_det)\n",
    "    #print(intersection)\n",
    "    return intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12c6cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_list = []\n",
    "\n",
    "# Get different values of column 'frame' and sort them\n",
    "frames = df_gt['frame'].unique()\n",
    "frames.sort()\n",
    "\n",
    "# Create loading bar\n",
    "loading_bar = tqdm(total=len(frames))\n",
    "\n",
    "# Iterate over frames\n",
    "for frame in frames:\n",
    "    # Iterate over the df_gt rows with the same 'frame' value\n",
    "    for index_gt, row_gt in df_gt[df_gt['frame'] == frame].iterrows():\n",
    "        best_overlap = None\n",
    "        # Iterate over the df_detections rows with the same 'frame' value and the same 'type' value\n",
    "        for index_det, row_det in df_detections[(df_detections['frame'] == frame) &\n",
    "                                                (df_detections['type'] == row_gt['type'])].iterrows():\n",
    "            # If row_gt['type'] == 'Car'\n",
    "            if row_gt['type'] == 'Car':\n",
    "                # If the bounding boxes 2D have an overlap greater than 0.7\n",
    "                if bbox_2d_overlap((row_gt['left'], row_gt['top'], row_gt['right'], row_gt['bottom']),\n",
    "                                   (row_det['left'], row_det['top'], row_det['right'], row_det['bottom'])) > 0.7:\n",
    "                    # Store the best overlaping bounding box\n",
    "                    best_overlap = row_det\n",
    "            # If row_gt['type'] == 'Pedestrian' or row_gt['type'] == 'Cyclist'\n",
    "            else:\n",
    "                # If the bounding boxes 2D have an overlap greater than 0.5\n",
    "                if bbox_2d_overlap((row_gt['left'], row_gt['top'], row_gt['right'], row_gt['bottom']),\n",
    "                                   (row_det['left'], row_det['top'], row_det['right'], row_det['bottom'])) > 0.5:\n",
    "                    # Store the best overlaping bounding box\n",
    "                    best_overlap = row_det\n",
    "        # If best_overlap is None\n",
    "        if best_overlap is None:\n",
    "            continue\n",
    "        # If best_overlap is not None\n",
    "        else:\n",
    "            combined_list.append([row_gt['frame'], row_gt['id'], row_gt['type'], row_gt['left'], row_gt['top'],\n",
    "                                  row_gt['right'], row_gt['bottom'], row_gt['occluded'],\n",
    "                                  row_gt['truncated'], row_gt['distance'], best_overlap['type'],\n",
    "                                  best_overlap['left'], best_overlap['top'],\n",
    "                                  best_overlap['right'], best_overlap['bottom'],\n",
    "                                  best_overlap['score']])\n",
    "    # Update loading bar\n",
    "    loading_bar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4fcb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.DataFrame(columns=['frame','id','type_gt','left_gt','top_gt','right_gt',\n",
    "                                    'bottom_gt','occluded_gt','truncated_gt','distance_gt','type_yolo','left_yolo',\n",
    "                                    'top_yolo','right_yolo','bottom_yolo','score_yolo'],\n",
    "                           data=combined_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db436881",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849d83f9",
   "metadata": {},
   "source": [
    "# Evaluate final method using YOLOv5 detections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3227f2",
   "metadata": {},
   "source": [
    "## Create final model pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbd8a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_0(x):\n",
    "        return a\n",
    "\n",
    "def objective_const(x, a):\n",
    "        return a\n",
    "\n",
    "def objective_log_f(x, a, b, c):\n",
    "    return a * np.log(x)**b + c\n",
    "\n",
    "def objective_2f(x, a, b, c):\n",
    "    return a * x**2 + b * x + c\n",
    "\n",
    "def objective_3f(x, a, b, c, d):\n",
    "    return a * x**3 + b * x**2 + c * x + d\n",
    "\n",
    "def objective_4f(x, a, b, c, d, e):\n",
    "    return a * x**4 + b * x**3 + c * x**2 + d * x + e\n",
    "\n",
    "def objective_5f(x, a, b, c, d, e, f):\n",
    "    return a * x**5 + b * x**4 + c * x**3 + d * x**2 + e * x + f\n",
    "\n",
    "def objective_6f(x, a, b, c, d, e, f, g):\n",
    "    return a * x**6 + b * x**5 + c * x**4 + d * x**3 + e * x**2 + f * x + g\n",
    "\n",
    "def objective_7f(x, a, b, c, d, e, f, g, h):\n",
    "    return a * x**7 + b * x**6 + c * x**5 + d * x**4 + e * x**3 + f * x**2 + g * x + h\n",
    "\n",
    "def objective_8f(x, a, b, c, d, e, f, g, h, i):\n",
    "    return a * x**8 + b * x**7 + c * x**6 + d * x**5 + e * x**4 + f * x**3 + g * x**2 + h * x + i\n",
    "\n",
    "def objective_9f(x, a, b, c, d, e, f, g, h, i, j):\n",
    "    return a * x**9 + b * x**8 + c * x**7 + d * x**6 + e * x**5 + f * x**4 + g * x**3 + h * x**2 + i * x + j\n",
    "\n",
    "class Regression_model:\n",
    "    def __init__(self, function, variables):\n",
    "        self.function = function\n",
    "        self.variables = variables\n",
    "    def __str__(self):\n",
    "        return \"function = %s, variables = %s\"%(self.function, self.variables)\n",
    "\n",
    "class Regression_model_class:\n",
    "    def __init__(self, model_car, model_pedestrian, model_cyclist):\n",
    "        self.car = model_car\n",
    "        self.pedestrian = model_pedestrian\n",
    "        self.cyclist = model_cyclist\n",
    "    def __str__(self):\n",
    "        return \"car: {%s},\\npedestrian: {%s},\\ncyclist: {%s}\"%(self.car, self.pedestrian, self.cyclist)\n",
    "        \n",
    "class Regression_model_bb:\n",
    "    def __init__(self, bb_complete, bb_incomplete):\n",
    "        self.bb_complete = bb_complete\n",
    "        self.bb_incomplete = bb_incomplete\n",
    "    def __str__(self):\n",
    "        return \"bb_complete: {%s},\\nbb_incomplete: {%s}\"%(self.bb_complete, self.bb_incomplete)\n",
    "    \n",
    "class Regression_model_error:\n",
    "    def __init__(self, height_distance, height_2d, pointcloud_distance, pointcloud_n_points):\n",
    "        self.height_distance = height_distance\n",
    "        self.height_2d = height_2d\n",
    "        self.pointcloud_distance = pointcloud_distance\n",
    "        self.pointcloud_n_points = pointcloud_n_points\n",
    "    def __str__(self):\n",
    "        return \"height_distance: {%s},\\nheight_2d: {%s},\\npointcloud_distance: {%s},\\npointcloud_n_points: {%s}\"%\\\n",
    "                                (self.height_distance, self.height_2d, self.pointcloud_distance, self.pointcloud_n_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0de28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "height_model = None\n",
    "pc_proj_refinement_model = None\n",
    "error_model = None\n",
    "\n",
    "with open('height_model.pkl', 'rb') as f:\n",
    "    height_model = pickle.load(f)\n",
    "with open('pc_proj_refinement_model.pkl', 'rb') as f:\n",
    "    pc_proj_refinement_model = pickle.load(f)\n",
    "with open('error_model.pkl', 'rb') as f:\n",
    "    error_model = pickle.load(f)\n",
    "    \n",
    "distance_models = {'height_model':height_model,\n",
    "                   'pc_proj_refinement_model':pc_proj_refinement_model,\n",
    "                   'error_model':error_model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77637b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def approximate_distance_height(type_name, top, bottom, bb_complete, model):\n",
    "    height = bottom - top\n",
    "    if type_name == 'Car':\n",
    "        if bb_complete:\n",
    "            f = model.car.bb_complete.function\n",
    "            return f(height, *model.car.bb_complete.variables)\n",
    "        else:\n",
    "            f = model.car.bb_incomplete.function\n",
    "            return f(height, *model.car.bb_incomplete.variables)\n",
    "    elif type_name == 'Pedestrian':\n",
    "        f = model.pedestrian.function\n",
    "        return f(height, *model.pedestrian.variables)\n",
    "    elif type_name == 'Cyclist':\n",
    "        f = model.cyclist.function\n",
    "        return f(height, *model.cyclist.variables)\n",
    "    else:\n",
    "        raise ValueError(\"Type must be Car, Pedestrian or Cyclist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6570d140",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(image_id):\n",
    "    name = '%06d'%image_id # 6 digit zeropadding\n",
    "    img = KITTI_DATASET+'images/'+name+'.png'\n",
    "    png = mpimg.imread(img)\n",
    "    return png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db0f305",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_point_cloud_projected(image_id):\n",
    "    name = '%06d'%image_id # 6 digit zeropadding\n",
    "    binary = KITTI_DATASET+'velodyne/'+name+'.bin'\n",
    "    with open(KITTI_DATASET+'calib/'+name+'.txt','r') as f:\n",
    "        calib = f.readlines()\n",
    "\n",
    "    # P2 (3 x 4) for left eye (intrinsic matrix in homogeneous coordinates)\n",
    "    P2 = np.matrix([float(x) for x in calib[2].strip('\\n').split(' ')[1:]]).reshape(3,4)\n",
    "    R0_rect = np.matrix([float(x) for x in calib[4].strip('\\n').split(' ')[1:]]).reshape(3,3)\n",
    "    # Add a 1 in bottom-right, reshape to 4 x 4\n",
    "    R0_rect = np.insert(R0_rect,3,values=[0,0,0],axis=0)\n",
    "    R0_rect = np.insert(R0_rect,3,values=[0,0,0,1],axis=1)\n",
    "    Tr_velo_to_cam = np.matrix([float(x) for x in calib[5].strip('\\n').split(' ')[1:]]).reshape(3,4)\n",
    "    Tr_velo_to_cam = np.insert(Tr_velo_to_cam,3,values=[0,0,0,1],axis=0)\n",
    "\n",
    "    # read raw data from binary\n",
    "    scan = np.fromfile(binary, dtype=np.float32).reshape((-1,4))\n",
    "    points = scan[:, 0:3] # lidar xyz (front, left, up)\n",
    "    # TODO: use fov filter? \n",
    "    velo = np.insert(points,3,1,axis=1).T\n",
    "    velo = np.delete(velo,np.where(velo[0,:]<0),axis=1)\n",
    "    \n",
    "    cam = P2 * R0_rect * Tr_velo_to_cam * velo\n",
    "    cam = np.delete(cam,np.where(cam[2,:]<0)[1],axis=1)\n",
    "    # get u,v,z\n",
    "    cam[:2] /= cam[2,:]\n",
    "    png = get_image(image_id)\n",
    "    IMG_H,IMG_W,_ = png.shape\n",
    "    # filter point out of canvas\n",
    "    u,v,z = cam\n",
    "    u_out = np.logical_or(u<0, u>IMG_W)\n",
    "    v_out = np.logical_or(v<0, v>IMG_H)\n",
    "    outlier = np.logical_or(u_out, v_out)\n",
    "    cam = np.delete(cam,np.where(outlier),axis=1)\n",
    "    return cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb67f642",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_projected_pcs_bb(lefts2d, tops2d, rights2d, bottoms2d, projected_pc):\n",
    "    projected_pcs_bb = []\n",
    "    for left, top, right, bottom in zip(lefts2d, tops2d, rights2d, bottoms2d):\n",
    "        filter_bb = (left < projected_pc[0,:]) & (top < projected_pc[1,:]) &\\\n",
    "            (projected_pc[0,:] < right) & (projected_pc[1,:] < bottom)\n",
    "        pc_distance_bb = projected_pc[2,:][filter_bb]\n",
    "        # Points on bb\n",
    "        projected_pcs_bb.append(pc_distance_bb)\n",
    "        # Deleting saved points\n",
    "        filter_intersection = (left < projected_pc[0,:]) &\\\n",
    "                       (top < projected_pc[1,:]) &\\\n",
    "                       (projected_pc[0,:] < right) &\\\n",
    "                       (projected_pc[1,:] < bottom)\n",
    "        projected_pc = np.concatenate((projected_pc[0,:][~filter_intersection],\\\n",
    "                                       projected_pc[1,:][~filter_intersection],\\\n",
    "                                       projected_pc[2,:][~filter_intersection]), axis=0)\n",
    "    return projected_pcs_bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1363efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def approximate_distance_pc(bbs_complete, tops2d, bottoms2d, types, projected_pcs_bb, model, height_model):\n",
    "    # Sort bbs by height (change to sort by regression method using height)\n",
    "    id_bbs = sorted(list(range(len(tops2d))),\n",
    "                    key=lambda i: approximate_distance_height(types[i], tops2d[i], bottoms2d[i],\n",
    "                                                              bbs_complete[i], height_model))\n",
    "    # Create enumare lists\n",
    "    types = list(enumerate(types))\n",
    "    tops2d = list(enumerate(tops2d))\n",
    "    bottoms2d = list(enumerate(bottoms2d))\n",
    "    # Order using the enumeration\n",
    "    types.sort(key=lambda x: id_bbs.index(x[0]))\n",
    "    tops2d.sort(key=lambda x: id_bbs.index(x[0]))\n",
    "    bottoms2d.sort(key=lambda x: id_bbs.index(x[0]))\n",
    "    # Save only the intial lists\n",
    "    types = list(map(lambda x: x[1], types))\n",
    "    tops2d = list(map(lambda x: x[1], tops2d))\n",
    "    bottoms2d = list(map(lambda x: x[1], bottoms2d))\n",
    "        \n",
    "    # Function to map all bbs\n",
    "    def get_distances_pc(type_name, top, bottom, pc_distance_bb):\n",
    "        if pc_distance_bb.size != 0: # Checks if there's any point on the bb 2D\n",
    "            # Approximate distance\n",
    "            distance = np.median(np.squeeze(np.asarray(pc_distance_bb)))\n",
    "            height = bottom - top\n",
    "            if type_name == 'Car':\n",
    "                f = model.car.function\n",
    "                rectification = f(distance, *model.car.variables)\n",
    "                distance += rectification\n",
    "            elif type_name == 'Pedestrian':\n",
    "                f = model.pedestrian.function\n",
    "                rectification = f(distance, *model.pedestrian.variables)\n",
    "                distance += rectification\n",
    "            elif type_name == 'Cyclist':\n",
    "                f = model.cyclist.function\n",
    "                rectification = f(distance, *model.cyclist.variables)\n",
    "                distance += rectification\n",
    "            else:\n",
    "                print(\"Type must be Car, Pedestrian or Cyclist\")\n",
    "            return distance\n",
    "        else:\n",
    "            return -1\n",
    "    # Map over bbs to get distance\n",
    "    distances = map(lambda type_name, top2d, bottom2d, pc_distance_bb: get_distances_pc(type_name, top2d, bottom2d, pc_distance_bb),\n",
    "                    types, tops2d, bottoms2d, projected_pcs_bb)\n",
    "    \n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c299dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ajust_distance(error_model, height_distance, height_2d, pointcloud_distance, pointcloud_n_points, class_name):\n",
    "    if pointcloud_distance == None:\n",
    "        return height_distance\n",
    "    else:\n",
    "        height_distance_model, height_2d_model, pointcloud_distance_model, pointcloud_n_points_model = None, None, None, None\n",
    "        # Obtain regression models based on the object type\n",
    "        if class_name == 'Car':\n",
    "            height_distance_model = error_model.height_distance.car\n",
    "            height_2d_model = error_model.height_2d.car\n",
    "            pointcloud_distance_model = error_model.pointcloud_distance.car\n",
    "            pointcloud_n_points_model = error_model.pointcloud_n_points.car\n",
    "        elif class_name == 'Cyclist':\n",
    "            height_distance_model = error_model.height_distance.cyclist\n",
    "            height_2d_model = error_model.height_2d.cyclist\n",
    "            pointcloud_distance_model = error_model.pointcloud_distance.cyclist\n",
    "            pointcloud_n_points_model = error_model.pointcloud_n_points.cyclist\n",
    "        elif class_name == 'Pedestrian':\n",
    "            height_distance_model = error_model.height_distance.pedestrian\n",
    "            height_2d_model = error_model.height_2d.pedestrian\n",
    "            pointcloud_distance_model = error_model.pointcloud_distance.pedestrian\n",
    "            pointcloud_n_points_model = error_model.pointcloud_n_points.pedestrian\n",
    "        else:\n",
    "            raise ValueError(\"Type must be Car, Pedestrian or Cyclist\")   \n",
    "        # Obtain an approximate error based on different metrics\n",
    "        height_distance_error = height_distance_model.function(height_distance, *height_distance_model.variables)\n",
    "        height_2d_error = height_2d_model.function(height_2d, *height_2d_model.variables)\n",
    "        pointcloud_distance_error = pointcloud_distance_model.function(pointcloud_distance, *pointcloud_distance_model.variables)\n",
    "        pointcloud_n_points_error = pointcloud_n_points_model.function(pointcloud_n_points, *pointcloud_n_points_model.variables)\n",
    "        # Obtain final distance to use\n",
    "        sum_error = height_distance_error + height_2d_error + pointcloud_distance_error + pointcloud_n_points_error\n",
    "        distance = (1 - (height_distance_error + height_2d_error)/sum_error) * height_distance +\\\n",
    "                   (1 - (pointcloud_distance_error + pointcloud_n_points_error)/sum_error) * pointcloud_distance\n",
    "        return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164d4c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def approximate_distance(image, pc_projected, types, lefts2d, tops2d, rights2d, bottoms2d, distance_models):\n",
    "    WIDTH_IMAGE = image.shape[1]\n",
    "    bbs_complete = list(map(lambda left, right: False if left <= 0 or right >= WIDTH_IMAGE-1 else True,\n",
    "                       lefts2d, rights2d))\n",
    "    approx_distances_height = list(map(lambda type_name, top, bottom, bb_complete: approximate_distance_height(type_name, top, bottom, bb_complete, distance_models['height_model']),\n",
    "                                       types, tops2d, bottoms2d, bbs_complete))\n",
    "    bbs_pc_n_points = get_projected_pcs_bb(lefts2d, tops2d, rights2d, bottoms2d, pc_projected)\n",
    "    approx_distances_pc = approximate_distance_pc(bbs_complete, tops2d, bottoms2d, types, bbs_pc_n_points, distance_models['pc_proj_refinement_model'], distance_models['height_model'])\n",
    "    approx_distances_ensemble = list(map(lambda height_distance, top, bottom, pc_distance, pc_n_points, class_name: ajust_distance(distance_models['error_model'], height_distance, bottom-top, pc_distance, pc_n_points.shape[1], class_name),\n",
    "                                         approx_distances_height, tops2d, bottoms2d, approx_distances_pc, bbs_pc_n_points, types))\n",
    "    return approx_distances_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e24aba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def approximate_distance_frame(frame, models):\n",
    "    image = get_image(frame)\n",
    "    pc_projected = get_point_cloud_projected(frame)\n",
    "    df_frame = df_combined[df_combined['frame'] == frame]\n",
    "    types = df_frame['type_yolo'].tolist()\n",
    "    lefts2d = df_frame['left_yolo'].tolist()\n",
    "    tops2d = df_frame['top_yolo'].tolist()\n",
    "    rights2d = df_frame['right_yolo'].tolist()\n",
    "    bottoms2d = df_frame['bottom_yolo'].tolist()\n",
    "    distance_models = models\n",
    "    # Calculate distance approximations\n",
    "    #start = time.time()\n",
    "    distance = approximate_distance(image, pc_projected, types, lefts2d, tops2d, rights2d, bottoms2d, distance_models)\n",
    "    #print(time.time() - start)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111c378b",
   "metadata": {},
   "outputs": [],
   "source": [
    "approximate_distance_frame(7480, distance_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8306be89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc24204",
   "metadata": {},
   "source": [
    "## Execute final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb5b112",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_approx = list(map(lambda x: approximate_distance_frame(x, distance_models), df_combined['frame'].unique().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c143c826",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "distance_approx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d3b973",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_approx = reduce(lambda a, b: a+b, distance_approx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da569205",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_approx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b05754",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined['distance_approx'] = distance_approx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674051e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18266069",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined['distance_error'] = df_combined['distance_approx'] - df_combined['distance_gt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b35eb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.plot(x='score_yolo', y='distance_error', kind='scatter', s=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2ef820",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5c656b",
   "metadata": {},
   "source": [
    "# MSE of the distance by KITTI difficulties and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7aede5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_difficulty(row):\n",
    "    height = row['bottom_gt'] - row['top_gt']\n",
    "    occlusion = row['occluded_gt']\n",
    "    truncation = row['truncated_gt']\n",
    "    if(height >= 40 and occlusion == 0 and truncation <= 0.15):\n",
    "        return 0\n",
    "    elif(height >= 25 and occlusion <= 1 and truncation <= 0.3):\n",
    "        return 1\n",
    "    elif(height >= 25 and occlusion <= 2 and truncation <= 0.5):\n",
    "        return 2\n",
    "    else:\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f0d1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined['difficulty'] = df_combined.apply(lambda row: define_difficulty(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d90a347",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fa90a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "difficulties = [0, 1, 2]                       \n",
    "classes = [\"Car\",\"Cyclist\",\"Pedestrian\"]\n",
    "text_difficulties = [\"Easy\", \"Moderate\", \"Hard\"]\n",
    "\n",
    "print(\"################################\", end=\"\\n\\n\")\n",
    "\n",
    "# Iterate over difficulties\n",
    "for difficulty, text_difficulty in zip(difficulties, text_difficulties):\n",
    "    # Iterate over classes\n",
    "    for class_name in classes:                  \n",
    "        df_difficulty = df_combined[(df_combined['difficulty'] <= difficulty) & (df_combined['type_yolo'] == class_name)]\n",
    "        start_time = time.time()\n",
    "        mse = mean_squared_error(df_difficulty['distance_gt'].tolist(),\n",
    "                                          df_difficulty['distance_approx'].tolist())\n",
    "        print(\"--- %s seconds to calculate MSE, %s difficulty, %s class  ---\" % (time.time() - start_time, text_difficulty, class_name))\n",
    "\n",
    "        print(\"\\nMean of all MSE by frame, %s difficulty, %s class = %s\\n\" % (text_difficulty, class_name, mse))\n",
    "\n",
    "    print(\"################################\", end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9f476b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
